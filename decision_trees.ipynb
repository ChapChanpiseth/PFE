{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First steps with the decision trees in Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Team Members**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classification with all the features of Iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import machine learning libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the library to draw the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the package python-graphviz\n",
    "import graphviz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _map_class(X_target):\n",
    "    \"\"\" Convert string to float\n",
    "    \"\"\"\n",
    "    \n",
    "    class_range = [1.5, 2.5, 3.5, 4.5, 5]\n",
    "    pre_val = 0\n",
    "    if X_target > 0 and X_target <= 1.5:\n",
    "        return 1\n",
    "    elif X_target > 1.5 and X_target <= 2.5:\n",
    "        return 2\n",
    "    elif X_target > 2.5 and X_target <= 3.5:\n",
    "        return 3\n",
    "    elif X_target > 3.5 and X_target <= 4.5:\n",
    "        return 4\n",
    "    elif X_target > 4.5:\n",
    "        return 5\n",
    "    \n",
    "#_map_class(2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ITU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4\n",
      "1    5\n",
      "2    3\n",
      "3    4\n",
      "4    2\n",
      "Name: QoE_ITU_JT_046_VP9_1280x780, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r\"/Volumes/D/py-workspace/PFE/dataset/Input/outband_QoS_ITU-QoE.csv\")\n",
    "data = data.dropna()\n",
    "\n",
    "# print(data['QoE_ITU_JT_046_VP9_1280x780'].head(5))\n",
    "\n",
    "# Map Continuous target to class\n",
    "data['QoE_ITU_JT_046_VP9_1280x780'] = data['QoE_ITU_JT_046_VP9_1280x780'].apply(lambda x: str(_map_class(x)))\n",
    "\n",
    "X = data.drop(['QoE_ITU_JT_046_VP9_1280x780', 'outbandQoS_RTT_STD (ms)'] , axis='columns') # attributes\n",
    "y = data['QoE_ITU_JT_046_VP9_1280x780'] # labels\n",
    "\n",
    "#data.head(5)\n",
    "print(y.head(5))\n",
    "#X.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['outbandQoS_DL_TP (kbps)' 'outbandQoS_UL_TP (kbps)' 'outbandQoS_RTT (ms)'\n",
      " 'outbandQoS_LOSS (ratio)']\n"
     ]
    }
   ],
   "source": [
    "print(X.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the label names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(iris.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting into train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1: What is the role of the seed?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10451,)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting random seed\n",
    "seed = 100\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.34, random_state = seed )\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, random_state = seed)\n",
    "\n",
    "X_train.head(5)\n",
    "y_train.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data type investigation\n",
    "- preprocessing.LabelEncoder() - convert string or float values to 0 .. n classes.\n",
    "- If we put as imput training_data_X, training_scores_Y to fit method it cause error. To avoid it we will convert and encode labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "# from sklearn import utils\n",
    "# lab_enc = preprocessing.LabelEncoder()\n",
    "# y_train_encoded = lab_enc.fit_transform(y_train)\n",
    "# print(y_train_encoded)\n",
    "# print(utils.multiclass.type_of_target(y_train))\n",
    "# print(utils.multiclass.type_of_target(y_train.astype('int')))\n",
    "# print(utils.multiclass.type_of_target(y_train_encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn a decision tree with the iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2: what is the criterion used to split a node?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=100,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=None, splitter='random')\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion='gini',splitter='random',min_samples_split=100)\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3: Train the decision tree.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the cell...\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the tree into a pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "# graph = graphviz.Source(dot_data) \n",
    "# graph\n",
    "# #graph.render(\"itu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4: Explain the content presented in each node. What does it mean?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "#                          feature_names= X_train.columns.values,  \n",
    "#                          class_names=y_train.columns.values,\n",
    "#                          filled=True, rounded=True,  \n",
    "#                          special_characters=True)  \n",
    "# graph = graphviz.Source(dot_data)  \n",
    "# graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5: Compute the accuracy on the training dataset and the test dataset?.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier test accuracy score: 0.6700794182374893\n"
     ]
    }
   ],
   "source": [
    "# Complete this cell...\n",
    "# X_train, X_test, y_train, y_test\n",
    "#accuracy_train = clf.score(X_train, y_train, sample_weight=None)\n",
    "accuracy_test = clf.score(X_test, y_test, sample_weight=None)\n",
    "#print('DecisionTreeClassifier training accuracy score: {}'.format(accuracy_train))\n",
    "print('DecisionTreeClassifier test accuracy score: {}'.format(accuracy_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6: We observe a gap between the training accuracy and the testing accuracy. What does it mean? Propose a simple modification of the code to reduce this gap.**\n",
    "\n",
    "### Score: Calculate the mean accuracy on the given test data and labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6 Answer:** My answer is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classification with only two features of Iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We would like to understand more precisely the behavior of the decision tree.\n",
    "For this purpose, we want to study the decision regions learned by the decision tree.\n",
    "Since it is simpler in 2D, we will study only 2 attributes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study just one pair of attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7: Select only the two attributes 'sepal length (cm)' and 'petal width (cm)'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complter the cell. You msut respect what is already written.\n",
    "# ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
    "pair = [0, 3]\n",
    "X_train2D = X_train[:, pair]\n",
    "X_test2D = X_test[:, pair]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8: Train the decision tree on the reduced dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2D = tree.DecisionTreeClassifier()\n",
    "# Complete the cell...\n",
    "clf2D = clf2D.fit(X_train2D, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracies for only two attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9: Compute the training and testing accuracies.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell...\n",
    "# X_train, X_test, y_train, y_test\n",
    "accuracy_train2D = clf2D.score(X_train2D, y_train, sample_weight=None)\n",
    "accuracy_test2D = clf2D.score(X_test2D, y_test, sample_weight=None)\n",
    "print('DecisionTreeClassifier training accuracy score: {}'.format(accuracy_train2D))\n",
    "print('DecisionTreeClassifier test accuracy score: {}'.format(accuracy_test2D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the decision regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "plot_step = 0.02\n",
    "n_classes = iris.target_names.shape[0]\n",
    "plot_colors = \"bry\" # colors assigned to the labels\n",
    "\n",
    "# Sampling the 2D plane\n",
    "x_min, x_max = X_train2D[:, 0].min() - 1, X_train2D[:, 0].max() + 1\n",
    "y_min, y_max = X_train2D[:, 1].min() - 1, X_train2D[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step), np.arange(y_min, y_max, plot_step))\n",
    "\n",
    "# Compute the decisions\n",
    "Z = clf2D.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape) # reshape as a 2D matrix\n",
    "\n",
    "# Plot the decision contours\n",
    "cs = plt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu)\n",
    "\n",
    "# Change the axis names\n",
    "plt.xlabel(iris.feature_names[pair[0]])\n",
    "plt.ylabel(iris.feature_names[pair[1]])\n",
    "plt.axis()\n",
    " \n",
    "# Plot the training points\n",
    "for i, color in zip(range(n_classes), plot_colors):\n",
    "    idx = np.where(y_train == i)\n",
    "    plt.scatter(X_train2D[idx, 0], X_train2D[idx, 1], c=color,\n",
    "                 label=iris.target_names[i],\n",
    "                 cmap=plt.cm.RdYlBu)\n",
    "# Put a legend\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10: draw the decision tree with graphviz. Is it consistent with the decision regions plot above?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10 Answer:** My answer is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data2D = tree.export_graphviz(clf2D, out_file=None, \n",
    "                         feature_names=np.array(iris.feature_names)[pair],  \n",
    "                         class_names=iris.target_names,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)\n",
    "\n",
    "graph2D = graphviz.Source(dot_data2D)  \n",
    "graph2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Selection of a classification model with all the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q11: Evaluate the accuracy of the classification with a cross-validation.**\n",
    "\n",
    "**Use a 10-fold cross-validation to assess your decision tree.**\n",
    "\n",
    "**Print the mean accuracy over the 10 folds and its standard-deviation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(tree.DecisionTreeClassifier(), X, y, cv=10)\n",
    "print(\"Mean accuracy: %0.2f (+/- %0.5f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q12: Use a grid search to test all possible values max_depth (from 1 to 8) of a tree classifier.**\n",
    "\n",
    "**For each search, you will use a 5-fold cross-validation.**\n",
    "\n",
    "**The score will be the accuracy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Complete this cell\n",
    "parameters = {'max_depth': range(1, 8)}\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "gs = GridSearchCV(clf, parameters, cv=5)\n",
    "gs = gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q13: print the mean scores of all the tested models.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The mean scores: %s\" % (gs.cv_results_['mean_test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q14: print the standard-deviation of the score of all the tested models.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15: print the parameter of the best model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this cell..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
